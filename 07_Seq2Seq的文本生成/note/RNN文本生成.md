## 基于RNN的文本生成

### 1. 直接输入部分提示词, 然后逐渐根据RNN的后验概率进行目标词选择, 生成文本



## 更好的生成方法Seq2Seq
1) 编码器: 将输入通过编码RNN生成潜在特征H
2) 解码器: 将潜在特征H输入到解码RNN进行文本生成
3) LSTM所具有的记录特征, 不在解码与编码器间传播
4) 解码器采用argmax进行输出选择, (抛弃了充满不确定性的概率采样方法)

## Seq2Seq的提高精度方法
1) 反转(Reverse)输入数据, 拉近相关数据的梯度传导
2) 偷窥(Peeky), 将输入至解码层的潜在特征h, 最大化利用

## Seq2Seq的部分应用
1) 机器人聊天
2) 图片描述
3) 算法生成


